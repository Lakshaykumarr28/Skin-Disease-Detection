{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"gpuType":"V28","provenance":[],"include_colab_link":true},"accelerator":"TPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10703074,"sourceType":"datasetVersion","datasetId":6633006}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Importing necessary libraries","metadata":{"id":"gmIOz4CiiFUo"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom PIL import Image\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport os\nfrom tensorflow.keras.utils import to_categorical\nfrom glob import glob\n\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nimport tensorflow as tf\n\nfrom keras.utils import plot_model\nfrom tensorflow.keras.metrics import Recall\n\nfrom tensorflow.keras import layers\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.applications.densenet import DenseNet121\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras import backend as K\n\nimport pickle","metadata":{"id":"3gFS_iG9iI4L","ExecuteTime":{"end_time":"2024-05-04T09:07:48.223519Z","start_time":"2024-05-04T09:07:48.211476Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:21:17.972139Z","iopub.execute_input":"2025-02-10T10:21:17.972468Z","iopub.status.idle":"2025-02-10T10:21:22.742739Z","shell.execute_reply.started":"2025-02-10T10:21:17.972435Z","shell.execute_reply":"2025-02-10T10:21:22.741821Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# The Dataset","metadata":{"id":"Kz_A-hPwjCj8"}},{"cell_type":"markdown","source":"\n\nHAM10000_metadata.csv file is the main csv file that includes the data of all training images, the features of which are -\n1. Lesion_id\n2. Image_id\n3. Dx\n4.  Dx_type\n5.  Age\n6.  Sex\n7.  Localization\n\n","metadata":{"id":"3Tyzh6Pdie7G"}},{"cell_type":"code","source":"import os\nos.listdir(\"/kaggle/input\")\n\n# Reading the data from HAM_metadata.csv\ndf = pd.read_csv('/kaggle/input/ham10000/archive/HAM10000_metadata.csv')","metadata":{"id":"XzOjqztKihg2","ExecuteTime":{"end_time":"2024-05-04T09:07:48.319037Z","start_time":"2024-05-04T09:07:48.226724Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:21:22.744031Z","iopub.execute_input":"2025-02-10T10:21:22.744725Z","iopub.status.idle":"2025-02-10T10:21:22.802594Z","shell.execute_reply.started":"2025-02-10T10:21:22.744685Z","shell.execute_reply":"2025-02-10T10:21:22.801445Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"id":"T48c9twQi8O9","outputId":"62a84a0f-5f35-49ef-de8a-b5565d2777de","ExecuteTime":{"end_time":"2024-05-04T09:07:48.350606Z","start_time":"2024-05-04T09:07:48.319037Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:21:22.804780Z","iopub.execute_input":"2025-02-10T10:21:22.805059Z","iopub.status.idle":"2025-02-10T10:21:22.826233Z","shell.execute_reply.started":"2025-02-10T10:21:22.805035Z","shell.execute_reply":"2025-02-10T10:21:22.825274Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.dtypes","metadata":{"id":"fa3UZu_Fi9ky","outputId":"5f9267ac-f54e-4542-8746-1de09d3de8b3","ExecuteTime":{"end_time":"2024-05-04T09:07:48.366648Z","start_time":"2024-05-04T09:07:48.353981Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:21:22.827608Z","iopub.execute_input":"2025-02-10T10:21:22.827900Z","iopub.status.idle":"2025-02-10T10:21:22.840605Z","shell.execute_reply.started":"2025-02-10T10:21:22.827873Z","shell.execute_reply":"2025-02-10T10:21:22.839832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.describe()","metadata":{"id":"f8zdehWujMLN","outputId":"9cef61df-553b-4a5d-a1a5-bf40c2309ec7","ExecuteTime":{"end_time":"2024-05-04T09:07:48.398343Z","start_time":"2024-05-04T09:07:48.368878Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:21:22.841596Z","iopub.execute_input":"2025-02-10T10:21:22.841890Z","iopub.status.idle":"2025-02-10T10:21:22.872874Z","shell.execute_reply.started":"2025-02-10T10:21:22.841863Z","shell.execute_reply":"2025-02-10T10:21:22.871986Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"A statistical analysis of numerical attributes of the dataset (age)","metadata":{"id":"v-L_AusCode-"}},{"cell_type":"markdown","source":"### Data Cleaning and Management","metadata":{"id":"MhGFOkYVjXqT"}},{"cell_type":"markdown","source":"Removing NULL values from the dataset","metadata":{"id":"TJUnOEWboojc"}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"id":"wA7_g4xLjOor","outputId":"1ab03137-9195-48f6-88d5-f72003e96a78","ExecuteTime":{"end_time":"2024-05-04T09:07:48.430357Z","start_time":"2024-05-04T09:07:48.398343Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:21:22.873821Z","iopub.execute_input":"2025-02-10T10:21:22.874121Z","iopub.status.idle":"2025-02-10T10:21:22.883262Z","shell.execute_reply.started":"2025-02-10T10:21:22.874091Z","shell.execute_reply":"2025-02-10T10:21:22.882355Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"There are 57 NULL values in 'age' feature.\nRather than dropping the values, replacing NULL values with the mean of 'age'.","metadata":{"id":"0PBPKM6MoyIm"}},{"cell_type":"code","source":"df['age'].fillna( df['age'].mean()  , inplace = True)","metadata":{"id":"hJdbEaEpowkF","ExecuteTime":{"end_time":"2024-05-04T09:07:48.446440Z","start_time":"2024-05-04T09:07:48.430357Z"},"outputId":"145954b4-9167-4df4-bd64-975afa72f54b","trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:21:22.884292Z","iopub.execute_input":"2025-02-10T10:21:22.884643Z","iopub.status.idle":"2025-02-10T10:21:22.901356Z","shell.execute_reply.started":"2025-02-10T10:21:22.884609Z","shell.execute_reply":"2025-02-10T10:21:22.900425Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"id":"Go2SbQpmpSqk","outputId":"5114a3c9-fc58-409c-850c-6dfa232f9652","ExecuteTime":{"end_time":"2024-05-04T09:07:48.478640Z","start_time":"2024-05-04T09:07:48.446440Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:21:22.903924Z","iopub.execute_input":"2025-02-10T10:21:22.904214Z","iopub.status.idle":"2025-02-10T10:21:22.928691Z","shell.execute_reply.started":"2025-02-10T10:21:22.904186Z","shell.execute_reply":"2025-02-10T10:21:22.927872Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"All NULL values are now resolved.","metadata":{"id":"ScLWSV4upYae"}},{"cell_type":"markdown","source":"Now, Making a lesion type dictionary to map the lesion type to a dataframe column.","metadata":{"id":"dVu55KwrqIVW"}},{"cell_type":"code","source":"lesion_type_dict = {\n    'nv': 'Melanocytic nevi',\n    'mel': 'Melanoma',\n    'bkl': 'Benign keratosis-like lesions ',\n    'bcc': 'Basal cell carcinoma',\n    'akiec': 'Actinic keratoses',\n    'vasc': 'Vascular lesions',\n    'df': 'Dermatofibroma'\n}\n\nbase_skin_dir = '/kaggle/input/ham10000/archive'\n\n# Merge images from both folders into one dictionary\n\nimageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n                     for x in glob(os.path.join(base_skin_dir, '*', '*.jpg'))}","metadata":{"id":"KWZNkYQtpWhg","ExecuteTime":{"end_time":"2024-05-04T09:07:48.948522Z","start_time":"2024-05-04T09:07:48.485752Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:21:22.930333Z","iopub.execute_input":"2025-02-10T10:21:22.930574Z","iopub.status.idle":"2025-02-10T10:21:23.088291Z","shell.execute_reply.started":"2025-02-10T10:21:22.930550Z","shell.execute_reply":"2025-02-10T10:21:23.087451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['path'] = df['image_id'].map(imageid_path_dict.get)\ndf['cell_type'] = df['dx'].map(lesion_type_dict.get)\ndf['cell_type_idx'] = pd.Categorical(df['cell_type']).codes\ndf.head()","metadata":{"id":"Zez-o53Htkn1","outputId":"2cc8768e-1136-4dda-8470-dfdc453a7187","ExecuteTime":{"end_time":"2024-05-04T09:07:48.995577Z","start_time":"2024-05-04T09:07:48.952270Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:21:23.089230Z","iopub.execute_input":"2025-02-10T10:21:23.089498Z","iopub.status.idle":"2025-02-10T10:21:23.120215Z","shell.execute_reply.started":"2025-02-10T10:21:23.089478Z","shell.execute_reply":"2025-02-10T10:21:23.119250Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Image Preprocessing","metadata":{"id":"doe2ghSjYOCf"}},{"cell_type":"markdown","source":"We have to resize the images from dimensions : 400 * 600 * 3 to dimensions : 150 * 120 * 3 as the model might take a lot of time to run on large dimensions of images.","metadata":{"id":"_5k0qH_HYZY6"}},{"cell_type":"code","source":"df['image'] = df['path'].map(lambda x: np.asarray(Image.open(x).resize((224,224))))","metadata":{"id":"aoy94_qaYQ8J","ExecuteTime":{"end_time":"2024-05-04T09:09:41.744413Z","start_time":"2024-05-04T09:07:48.999262Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:21:23.120988Z","iopub.execute_input":"2025-02-10T10:21:23.121285Z","iopub.status.idle":"2025-02-10T10:24:20.937143Z","shell.execute_reply.started":"2025-02-10T10:21:23.121264Z","shell.execute_reply":"2025-02-10T10:24:20.936277Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Plotting some images from each class of dataset.","metadata":{"id":"dG7fwzsqYvFa"}},{"cell_type":"code","source":"n_samples = 5\nfig, m_axs = plt.subplots(7, n_samples, figsize = (4*n_samples, 3*7))\nfor n_axs, (type_name, type_rows) in zip(m_axs, df.sort_values(['cell_type']).groupby('cell_type')):\n    n_axs[0].set_title(type_name)\n    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state=2018).iterrows()):\n        c_ax.imshow(c_row['image'])\n        c_ax.axis('off')\nfig.savefig('category_samples.png', dpi=300)","metadata":{"id":"q-kLlu6KY0Ek","outputId":"8d7884a2-5e76-432a-ef7e-b176c6b9e8d7","ExecuteTime":{"end_time":"2024-05-04T09:09:51.652373Z","start_time":"2024-05-04T09:09:41.748289Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:24:20.938025Z","iopub.execute_input":"2025-02-10T10:24:20.938287Z","iopub.status.idle":"2025-02-10T10:24:31.273693Z","shell.execute_reply.started":"2025-02-10T10:24:20.938265Z","shell.execute_reply":"2025-02-10T10:24:31.272679Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# to check the image size distribution - It returns one row that shows all images are uniform\ndf['image'].map(lambda x: x.shape).value_counts()","metadata":{"id":"QalgWCo1Y4ZO","outputId":"73b7755b-0bf1-45c7-a8a4-dca88afe4546","ExecuteTime":{"end_time":"2024-05-04T09:09:51.683821Z","start_time":"2024-05-04T09:09:51.654537Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:24:31.275146Z","iopub.execute_input":"2025-02-10T10:24:31.275591Z","iopub.status.idle":"2025-02-10T10:24:31.289935Z","shell.execute_reply.started":"2025-02-10T10:24:31.275550Z","shell.execute_reply":"2025-02-10T10:24:31.289126Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features = df.drop(columns = ['cell_type_idx'], axis = 1)\ntarget = df['cell_type_idx']\n\nfeatures.head()","metadata":{"id":"XAqGiHGNS1Jx","outputId":"b35af7bc-f851-415f-d464-bd1a57490d5a","ExecuteTime":{"end_time":"2024-05-04T09:09:59.274010Z","start_time":"2024-05-04T09:09:51.686971Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:24:31.290802Z","iopub.execute_input":"2025-02-10T10:24:31.291011Z","iopub.status.idle":"2025-02-10T10:24:40.028316Z","shell.execute_reply.started":"2025-02-10T10:24:31.290994Z","shell.execute_reply":"2025-02-10T10:24:40.027460Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_train_o, x_test_o, y_train_o, y_test_o = train_test_split(features, target, test_size=0.25,random_state=666)\nunique_values = tf.unique(x_train_o.cell_type.values)","metadata":{"ExecuteTime":{"end_time":"2024-05-04T09:09:59.305821Z","start_time":"2024-05-04T09:09:59.275329Z"},"id":"rDNVAVTSNcUA","trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:24:40.029190Z","iopub.execute_input":"2025-02-10T10:24:40.029523Z","iopub.status.idle":"2025-02-10T10:24:40.385815Z","shell.execute_reply.started":"2025-02-10T10:24:40.029490Z","shell.execute_reply":"2025-02-10T10:24:40.385084Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_train = np.asarray(x_train_o['image'].tolist())\nx_test = np.asarray(x_test_o['image'].tolist())\n\nx_train_mean = np.mean(x_train)\nx_train_std = np.std(x_train)\n\nx_test_mean = np.mean(x_test)\nx_test_std = np.std(x_test)\n\nx_train = (x_train - x_train_mean)/x_train_std\nx_test = (x_test - x_test_mean)/x_test_std","metadata":{"ExecuteTime":{"end_time":"2024-05-04T09:10:01.868391Z","start_time":"2024-05-04T09:09:59.305821Z"},"id":"OEYTYA6FNcUB","trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:24:40.386630Z","iopub.execute_input":"2025-02-10T10:24:40.386935Z","iopub.status.idle":"2025-02-10T10:24:53.168920Z","shell.execute_reply.started":"2025-02-10T10:24:40.386905Z","shell.execute_reply":"2025-02-10T10:24:53.167936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Performing one-hot encoding on the labels\ny_train = to_categorical(y_train_o, num_classes = 7)\ny_test = to_categorical(y_test_o, num_classes = 7)\ny_test","metadata":{"ExecuteTime":{"end_time":"2024-05-04T09:10:01.900392Z","start_time":"2024-05-04T09:10:01.873040Z"},"id":"WnkcknVkNcUB","outputId":"6cb9cbe2-8f21-43ab-e699-d993dfc530a5","trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:24:53.169892Z","iopub.execute_input":"2025-02-10T10:24:53.170157Z","iopub.status.idle":"2025-02-10T10:24:53.177803Z","shell.execute_reply.started":"2025-02-10T10:24:53.170137Z","shell.execute_reply":"2025-02-10T10:24:53.176946Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size = 0.1, random_state = 999)\n\n# Reshaping images in 3 dimensions (height = 60, width = 75 , channel = 3)\nx_train = x_train.reshape(x_train.shape[0], *(224,224,3))\nx_test = x_test.reshape(x_test.shape[0], *(224,224,3))\nx_validate = x_validate.reshape(x_validate.shape[0], *(224,224,3))","metadata":{"ExecuteTime":{"end_time":"2024-05-04T09:10:02.285391Z","start_time":"2024-05-04T09:10:01.904947Z"},"id":"jJZhVdWyNcUB","trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:24:53.178678Z","iopub.execute_input":"2025-02-10T10:24:53.178967Z","iopub.status.idle":"2025-02-10T10:24:55.768764Z","shell.execute_reply.started":"2025-02-10T10:24:53.178938Z","shell.execute_reply":"2025-02-10T10:24:55.767957Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.ma.shape(x_train)","metadata":{"ExecuteTime":{"end_time":"2024-05-04T09:10:02.301390Z","start_time":"2024-05-04T09:10:02.285391Z"},"id":"tVM6YqUpNcUC","outputId":"2befa1e4-a052-43c2-d450-16975ea7a4a7","trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:24:55.769605Z","iopub.execute_input":"2025-02-10T10:24:55.769943Z","iopub.status.idle":"2025-02-10T10:24:55.774885Z","shell.execute_reply.started":"2025-02-10T10:24:55.769911Z","shell.execute_reply":"2025-02-10T10:24:55.774262Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.ma.shape(x_test)","metadata":{"ExecuteTime":{"end_time":"2024-05-04T09:10:02.318124Z","start_time":"2024-05-04T09:10:02.302500Z"},"id":"AFIjzAWoNcUC","outputId":"80994968-5273-4a3d-e2d3-f85db3f4d859","trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:24:55.775627Z","iopub.execute_input":"2025-02-10T10:24:55.775847Z","iopub.status.idle":"2025-02-10T10:24:55.795078Z","shell.execute_reply.started":"2025-02-10T10:24:55.775829Z","shell.execute_reply":"2025-02-10T10:24:55.794478Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# With data augmentation to prevent overfitting\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image\n        width_shift_range=0.12,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.12,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True)  # randomly flip images\n\ndatagen.fit(x_train)","metadata":{"ExecuteTime":{"end_time":"2024-05-04T09:10:02.785250Z","start_time":"2024-05-04T09:10:02.318124Z"},"id":"6cJ0UuV-NcUC","trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:24:55.796379Z","iopub.execute_input":"2025-02-10T10:24:55.796692Z","iopub.status.idle":"2025-02-10T10:24:58.743224Z","shell.execute_reply.started":"2025-02-10T10:24:55.796663Z","shell.execute_reply":"2025-02-10T10:24:58.742507Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.ma.shape(x_train)","metadata":{"ExecuteTime":{"end_time":"2024-05-04T09:10:02.800799Z","start_time":"2024-05-04T09:10:02.785250Z"},"id":"YG0z89-3NcUD","outputId":"690f7be7-d92e-4057-ac8d-74cba20b84d0","trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:24:58.744211Z","iopub.execute_input":"2025-02-10T10:24:58.744438Z","iopub.status.idle":"2025-02-10T10:24:58.749980Z","shell.execute_reply.started":"2025-02-10T10:24:58.744419Z","shell.execute_reply":"2025-02-10T10:24:58.749118Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy',\n                                            patience=3,\n                                            verbose=1,\n                                            factor=0.5,\n                                            min_lr=0.00001)","metadata":{"id":"ydStnQtmCsuC","trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:24:58.752584Z","iopub.execute_input":"2025-02-10T10:24:58.752816Z","iopub.status.idle":"2025-02-10T10:24:58.768105Z","shell.execute_reply.started":"2025-02-10T10:24:58.752798Z","shell.execute_reply":"2025-02-10T10:24:58.767471Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EfficientNet B1","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetB1\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\n\n# Load the EfficientNetB1 model, without the top (final classification) layer\nbase_model = EfficientNetB1(weights='imagenet', include_top=False, input_shape=(224, 224, 3))  \n\n# Add custom layers on top of EfficientNetB1\nx = base_model.output\nx = GlobalAveragePooling2D()(x)  # Global average pooling to reduce feature maps\nx = Dense(1024, activation='relu')(x)  # Fully connected layer for additional learning\npredictions = Dense(7, activation='softmax')(x)  # 7 classes for classification\n\n# Combine base model and new custom layers\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Freeze base model layers to retain pre-trained weights\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Compile the model with Adam optimizer\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Set up data generators for training and validation\ntrain_datagen = ImageDataGenerator(\n    rescale=1.0/255.0,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n)\n\n# Train model\nhistory = model.fit(x=x_train,\n                    y=y_train,\n                    epochs=10,\n                    batch_size=32,\n                    validation_data=(x_validate, y_validate),\n                    callbacks=learning_rate_reduction\n)\n\n# Optionally, unfreeze some layers of EfficientNetB1 base model for fine-tuning\nfor layer in base_model.layers[-30:]:  # Unfreeze the last 30 layers\n    layer.trainable = True\n\n# Recompile the model after unfreezing layers\nmodel.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Fine-tune model\nhistory_finetune = model.fit(x=x_train,\n                             y=y_train,\n                             epochs=5,\n                             batch_size=32,\n                             validation_data=(x_validate, y_validate),\n                             callbacks=learning_rate_reduction\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:24:58.769005Z","iopub.execute_input":"2025-02-10T10:24:58.769291Z","iopub.status.idle":"2025-02-10T10:30:38.894060Z","shell.execute_reply.started":"2025-02-10T10:24:58.769265Z","shell.execute_reply":"2025-02-10T10:30:38.892960Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accuracy = model.evaluate(x_train, y_train, verbose=1)[1]\nprint(\"Train accuracy = \", accuracy*100, \"%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:30:45.916891Z","iopub.execute_input":"2025-02-10T10:30:45.917264Z","execution_failed":"2025-02-10T10:30:35.406Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accuracy = model.evaluate(x_test, y_test, verbose=1)[1]\nprint(\"Test: accuracy = \",accuracy*100,\"%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:31:34.695486Z","iopub.execute_input":"2025-02-10T10:31:34.695844Z","iopub.status.idle":"2025-02-10T10:31:34.705371Z","shell.execute_reply.started":"2025-02-10T10:31:34.695813Z","shell.execute_reply":"2025-02-10T10:31:34.704248Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EfficientNetB0","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\n\n# Load the EfficientNetB0 model without the top classification layer\nbase_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Add custom layers on top of EfficientNetB0\nx = base_model.output\nx = GlobalAveragePooling2D()(x)  # Global average pooling reduces each feature map to a single value\nx = Dense(1024, activation='relu')(x)  # Dense layer to introduce trainable parameters\npredictions = Dense(7, activation='softmax')(x)  # 7 classes for skin diseases\n\n# Combine base model and new custom layers\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Freeze base model layers to retain pre-trained weights\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Compile model with Adam optimizer\n# instantiating the model in the strategy scope creates the model on the TPU\n\n\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Set up data generators for training and validation\ntrain_datagen = ImageDataGenerator(\n    rescale=1.0/255.0,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n)\n\n# Train model\nhistory = model.fit(x=x_train,\n                    y=y_train,\n                    epochs=10,\n                    batch_size=32,\n                    validation_data=(x_validate, y_validate),\n                    callbacks=learning_rate_reduction)\n\n# Optionally, unfreeze some layers of the EfficientNetB0 base model for fine-tuning\nfor layer in base_model.layers[-30:]:  # Unfreeze the last 30 layers\n    layer.trainable = True\n\n# Recompile model after unfreezing layers\n\nmodel.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Fine-tune model\nhistory_finetune = model.fit(x=x_train,\n                             y=y_train,\n                             epochs=5,\n                             batch_size=32,\n                             validation_data=(x_validate, y_validate),\n                             callbacks=learning_rate_reduction)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:07:01.559485Z","iopub.execute_input":"2025-02-10T10:07:01.559687Z","iopub.status.idle":"2025-02-10T10:11:15.803222Z","shell.execute_reply.started":"2025-02-10T10:07:01.559670Z","shell.execute_reply":"2025-02-10T10:11:15.802179Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accuracy = model.evaluate(x_train, y_train, verbose=1)[1]\nprint(\"Train accuracy = \", accuracy*100, \"%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:11:36.260429Z","iopub.execute_input":"2025-02-10T10:11:36.260750Z","iopub.status.idle":"2025-02-10T10:11:59.941568Z","shell.execute_reply.started":"2025-02-10T10:11:36.260724Z","shell.execute_reply":"2025-02-10T10:11:59.940727Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accuracy = model.evaluate(x_test, y_test, verbose=1)[1]\nprint(\"Test: accuracy = \",accuracy*100,\"%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:31:28.209449Z","iopub.status.idle":"2025-02-10T10:31:28.209762Z","shell.execute_reply":"2025-02-10T10:31:28.209649Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# Get predictions for the test set\ny_pred = model.predict(x_test)\ny_pred_classes = np.argmax(y_pred, axis=1)  # Convert predictions to class labels\ny_true_classes = np.argmax(y_test, axis=1)  # Convert one-hot encoded labels to class labels\n\n# Compute the confusion matrix\ncm = confusion_matrix(y_true_classes, y_pred_classes)\n\n# Define the class names based on the dataset (modify according to your specific classes)\nclass_names = ['Melanocytic nevi', 'Melanoma', 'Benign keratosis-like lesions',\n               'Basal cell carcinoma', 'Actinic keratoses', 'Vascular lesions', 'Dermatofibroma']\n\n# Plot the confusion matrix as a heatmap\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.show()\n\n# Optionally, print a classification report for more detailed metrics\nprint(classification_report(y_true_classes, y_pred_classes, target_names=class_names))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T10:13:18.302491Z","iopub.execute_input":"2025-02-10T10:13:18.302848Z","iopub.status.idle":"2025-02-10T10:13:37.385356Z","shell.execute_reply.started":"2025-02-10T10:13:18.302824Z","shell.execute_reply":"2025-02-10T10:13:37.384501Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# InceptionV3","metadata":{"id":"8YKWXIUdCjIR"}},{"cell_type":"code","source":"from tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\n\n# Load the InceptionV3 model, without the top (final classification) layer\nbase_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Add custom layers on top of InceptionV3\nx = base_model.output\nx = GlobalAveragePooling2D()(x)  # Global average pooling reduces each feature map to a single value\nx = Dense(1024, activation='relu')(x)  # Add a dense layer for more learnable parameters\npredictions = Dense(7, activation='softmax')(x)  # 7 classes for skin diseases\n\n# Combine base model and new custom layers\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Freeze base model layers to retain pre-trained weights\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Compile model with Adam optimizer\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Set up data generators for training and validation\ntrain_datagen = ImageDataGenerator(\n    rescale=1.0/255.0,  # Rescale pixel values from 0-255 to 0-1\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n)\n\n# Train model\nhistory = model.fit(x=x_train,\n                    y=y_train,\n                    epochs=10,\n                    batch_size=32,\n                    validation_data=(x_validate,y_validate),\n                    callbacks=learning_rate_reduction\n)\n\n# Optionally, unfreeze some layers of the InceptionV3 base model for fine-tuning\nfor layer in base_model.layers[-30:]:  # Unfreeze the last 30 layers\n    layer.trainable = True\n\n# Recompile model after unfreezing layers\nmodel.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Fine-tune model\nhistory_finetune = model.fit(x=x_train,\n                             y=y_train,\n                             epochs=5,\n                             batch_size=32,\n                             validation_data=(x_validate,y_validate),\n                             callbacks=learning_rate_reduction\n)\n","metadata":{"id":"rtqRr6D5Cm_x","outputId":"b3d6c0fb-8721-445f-c871-f1afba180332","trusted":true,"execution":{"iopub.status.busy":"2025-02-10T09:36:45.006065Z","iopub.execute_input":"2025-02-10T09:36:45.006376Z","iopub.status.idle":"2025-02-10T09:36:57.006728Z","shell.execute_reply.started":"2025-02-10T09:36:45.006351Z","shell.execute_reply":"2025-02-10T09:36:57.005556Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accuracy = model.evaluate(x_train, y_train, verbose=1)[1]\nprint(\"Train accuracy = \", accuracy*100, \"%\")","metadata":{"id":"GDyrsaFMHd63","outputId":"eaaec8f5-723b-4889-d0cc-1df3a8be740c","trusted":true,"execution":{"iopub.status.busy":"2025-02-10T09:36:40.930124Z","iopub.execute_input":"2025-02-10T09:36:40.930485Z","iopub.status.idle":"2025-02-10T09:36:41.001839Z","shell.execute_reply.started":"2025-02-10T09:36:40.930459Z","shell.execute_reply":"2025-02-10T09:36:41.000764Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accuracy = model.evaluate(x_test, y_test, verbose=1)[1]\nprint(\"Test: accuracy = \",accuracy*100,\"%\")","metadata":{"id":"t8owbWozHhtt","outputId":"6f07eadb-27b3-4d26-d250-0d4532fb32c2"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Saving the model","metadata":{"id":"nIfhyxORIDg8"}},{"cell_type":"code","source":"model.save('inceptionv3_model.h5')","metadata":{"id":"2qP5DWmrIFVC","outputId":"9b12e70d-cffe-4dd9-f2b7-9ad6e4aab465"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Predicting the class of a sample image. image class = \"Benign keratosis-like lesions\"","metadata":{"id":"Ov1yqOdKJDJ2"}},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image\n\n# Load the saved model\nmodel = load_model('/content/inceptionv3_model.h5')\n\n# Define the class indices dictionary\nclass_indices = {\n    0: 'Melanocytic nevi',\n    1: 'Melanoma',\n    2: 'Benign keratosis-like lesions',\n    3: 'Basal cell carcinoma',\n    4: 'Actinic keratoses',\n    5: 'Vascular lesions',\n    6: 'Dermatofibroma'\n}\n\n# Load and preprocess the image\ndef preprocess_image(img_path):\n    img = image.load_img(img_path, target_size=(224, 224))  # Target size for InceptionV3\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n    img_array = img_array / 255.0  # Rescale pixel values to [0, 1]\n    return img_array\n\n# Predict the class of a new image\ndef predict_image_class(img_path):\n    img_array = preprocess_image(img_path)\n    predictions = model.predict(img_array)  # Predict the class probabilities\n    predicted_class = np.argmax(predictions, axis=1)[0]  # Get the index of highest probability\n    class_name = class_indices[predicted_class]  # Map index to class name\n    return class_name\n\n# Example usage\nimg_path = '/content/ISIC_0024313.jpg'\nclass_name = predict_image_class(img_path)\nprint(f\"Predicted Class: {class_name}\")\n","metadata":{"id":"BqLTZ9jpIrm9","outputId":"9674ef9c-64f2-41a3-e302-71c165e3e9c1"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MobileNet V2","metadata":{"id":"c9Teib6IKrHS"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Set parameters\ninput_shape = (224, 224, 3)\nnum_classes = 7\n\n# Load the MobileNetV2 model with pre-trained ImageNet weights, exclude the top layer\nbase_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n\n# Freeze the base model's layers\nbase_model.trainable = False\n\n# Add custom layers for classification\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dropout(0.2)(x)  # Adding dropout to reduce overfitting\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.2)(x)  # Additional dropout layer\npredictions = Dense(num_classes, activation='softmax')(x)  # Final layer for classification\n\n# Create the complete model\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Data generators for training and validation\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Train the model\nepochs = 10  # You can adjust the number of epochs\nhistory = model.fit(x=x_train,\n                    y=y_train,\n                    epochs=10,\n                    batch_size=32,\n                    validation_data=(x_validate,y_validate),\n                    callbacks=learning_rate_reduction\n)\n\n# Unfreeze some layers and fine-tune\nbase_model.trainable = True\nfor layer in base_model.layers[:100]:  # Freeze the first 100 layers\n    layer.trainable = False\n\n# Re-compile and fine-tune\nmodel.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n\nfine_tune_epochs = 5\nhistory_finetune = model.fit(x=x_train,\n                             y=y_train,\n                             epochs=5,\n                             batch_size=32,\n                             validation_data=(x_validate,y_validate),\n                             callbacks=learning_rate_reduction\n)\n","metadata":{"id":"DdqSQFnVKvN1","outputId":"ff5367a0-bdde-4cf3-d818-b44a5d12d258"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accuracy = model.evaluate(x_train, y_train, verbose=1)[1]\nprint(\"Train accuracy = \", accuracy*100, \"%\")","metadata":{"id":"kllkN0k9hZQL","outputId":"a436e906-4057-4f9c-b744-7fc01b68c5c8"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accuracy = model.evaluate(x_test, y_test, verbose=1)[1]\nprint(\"Test: accuracy = \",accuracy*100,\"%\")","metadata":{"id":"XbTfIe2phcQE","outputId":"3692adfc-d671-47ec-99e7-c895314c6d35"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Saving the model","metadata":{"id":"gEr7Mt_WhfI-"}},{"cell_type":"code","source":"model.save('MobileNetV2_model.h5')","metadata":{"id":"1O38Wj9qhfv3","outputId":"2d85b614-4b9c-420b-fcf5-48cd1c5f79fe"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Implementation of CNN","metadata":{"id":"jJeCFsF9NcUD"}},{"cell_type":"markdown","source":"The CNN model : DenseNet 121\n\nOptimizer: SGD\n\nActivation function used: Softmax","metadata":{"id":"Bmt5RLWQNcUD"}},{"cell_type":"code","source":"from tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\n\n# Load the DenseNet121 model without the top layer\nbase_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Add custom layers on top of DenseNet121\nx = base_model.output\nx = GlobalAveragePooling2D()(x)  # Global average pooling reduces each feature map to a single value\nx = Dense(1024, activation='relu')(x)  # Dense layer for more learnable parameters\npredictions = Dense(7, activation='softmax')(x)  # 7 classes for skin diseases\n\n# Combine base model and new custom layers\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Freeze base model layers to retain pre-trained weights\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Compile model with Adam optimizer\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Set up data generators for training and validation\ntrain_datagen = ImageDataGenerator(\n    rescale=1.0/255.0,  # Rescale pixel values from 0-255 to 0-1\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n)\n\n# Train the model\nhistory = model.fit(\n    x=x_train,\n    y=y_train,\n    epochs=10,\n    batch_size=32,\n    validation_data=(x_validate, y_validate),\n    callbacks=[learning_rate_reduction]\n)\n\n# Optionally, unfreeze some layers of the DenseNet121 base model for fine-tuning\nfor layer in base_model.layers[-30:]:  # Unfreeze the last 30 layers\n    layer.trainable = True\n\n# Recompile model after unfreezing layers\nmodel.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Fine-tune model\nhistory_finetune = model.fit(\n    x=x_train,\n    y=y_train,\n    epochs=5,\n    batch_size=32,\n    validation_data=(x_validate, y_validate),\n    callbacks=[learning_rate_reduction]\n)\n","metadata":{"id":"RgSPgztXiySD","outputId":"ffc9632e-a4f3-4561-a077-919437fe42c9"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accuracy = model.evaluate(x_train, y_train, verbose=1)[1]\nprint(\"Train accuracy = \", accuracy*100, \"%\")","metadata":{"id":"qAf8VUa8i5NN","outputId":"1487ee4d-00f7-4117-bdd5-fd33b6c0a297"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accuracy = model.evaluate(x_test, y_test, verbose=1)[1]\nprint(\"Test: accuracy = \",accuracy*100,\"%\")","metadata":{"id":"XM9lXuY5i7sZ","outputId":"852f57fe-3496-4f10-a21d-78e700cffea5"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save('DenseNet121_model.h5')","metadata":{"id":"2i_2HMhPi-ZC"},"outputs":[],"execution_count":null}]}